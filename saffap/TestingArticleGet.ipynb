{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os \n",
    "import pandas as pd\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "from data_handler.models import Article\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sentiment.model import progress\n",
    "import plotly.express as px\n",
    "from sentiment.models import Category\n",
    "import sys\n",
    "from django.db.models import Avg, Count, Min, Sum\n",
    "from datetime import timedelta, date\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "all_articles = Article.objects.all()\n",
    "df = pd.read_csv(\"cleaned_docs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "length = len(all_articles)\n",
    "notfound = []\n",
    "for article in all_articles:\n",
    "    index += 1\n",
    "    progress(index, length, status=\"Article {}/{}\".format(index, length))\n",
    "    row = df.loc[df['headlines'] == article.headline]\n",
    "    value = row['clean_docs'].tolist()\n",
    "    if not value:\n",
    "        notfound.append(article)\n",
    "        continue\n",
    "    article.tokens = value[0]\n",
    "    article.save()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler.models import Category\n",
    "\n",
    "negativ = [entry['word'] for entry in list(Category.objects.get(name=\"Negativ\").words.all().values('word'))]\n",
    "neg = [entry['word'] for entry in list(Category.objects.get(name=\"Ngtv\").words.all().values('word'))]\n",
    "\n",
    "positiv = [entry['word'] for entry in list(Category.objects.get(name=\"Positiv\").words.all().values('word'))]\n",
    "pos = [entry['word'] for entry in list(Category.objects.get(name=\"Pstv\").words.all().values('word'))]\n",
    "\n",
    "ngtv = set(negativ+neg)\n",
    "pstv = set(positiv+pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "index = 0\n",
    "length = len(all_articles)\n",
    "cur_art = \"\"\n",
    "for article in all_articles:\n",
    "    index += 1\n",
    "    cur_art = article\n",
    "    progress(index, length, status=\"Article of {}/{}\".format(index, length))\n",
    "    tokens = word_tokenize(article.tokens)\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for token in tokens:\n",
    "        token = token.upper()\n",
    "        if token in ngtv:\n",
    "            neg += 1\n",
    "        elif token in pstv:\n",
    "            pos += 1\n",
    "    article.smarter_negative_words = neg\n",
    "    article.smarter_positive_words = pos\n",
    "    article.save()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment.model import preprocess\n",
    "\n",
    "class ArticleHeadlineIterator(object):\n",
    "    def __init__(self, articles):\n",
    "        self.articles = articles\n",
    "    def __iter__(self):\n",
    "        for article in self.articles:\n",
    "            yield article.headline\n",
    "\n",
    "class ArticleContentIterator(object):\n",
    "    def __init__(self, articles):\n",
    "        self.articles = articles\n",
    "    def __iter__(self):\n",
    "        for article in self.articles:\n",
    "            row = article.headline + \". \" + article.contents\n",
    "            yield row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_art.smarter_negative_words\n",
    "cur_art.smarter_positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cur_art.headline)\n",
    "art = df.loc[df['headlines']==cur_art.headline]\n",
    "# print(art)\n",
    "# cur_art.tokens = art['clean_docs'].tolist()[0]\n",
    "# cur_art.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentit = ArticleContentIterator(notfound)\n",
    "\n",
    "clean_articles = preprocess(contentit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlineit = ArticleHeadlineIterator(notfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in headlineit:\n",
    "    art = Article.objects.filter(headline=headline).first()\n",
    "    try:\n",
    "        art.delete()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.loc[df['headlines']=='How London\\'s loss is Dublin\\'s gain after Brexit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment    return\n",
      "date                           \n",
      "2016-01-04   0.095122 -0.008310\n",
      "2016-01-04   0.095122 -1.048494\n",
      "2016-01-04   0.095122 -0.006398\n",
      "2016-01-05   0.126354 -0.001299\n",
      "2016-01-05   0.126354 -0.003196\n",
      "[[ 0.09512195 -0.0083096 ]\n",
      " [ 0.09512195 -1.04849419]\n",
      " [ 0.09512195 -0.00639797]\n",
      " ...\n",
      " [ 0.08818058 -0.25662586]\n",
      " [ 0.08818058 -0.01142466]\n",
      " [ 0.08818058 -0.00482362]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d8c4f7f2c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautocorrelate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'aic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, maxlags, method, ic, trend, verbose)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0mselections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"%s not recognized, must be among %s\"\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36mselect_order\u001b[0;34m(self, maxlags, trend)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlags\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_criteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                 \u001b[0mics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/base/wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36minfo_criteria\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0mfree_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlag_order\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mneqs\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneqs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_exog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m         \u001b[0mld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdet_symm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_u_mle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \u001b[0;31m# See Lütkepohl pp. 146-150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tools/linalg.py\u001b[0m in \u001b[0;36mlogdet_symm\u001b[0;34m(m, check_symm)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# would be nice to short-circuit check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"m is not symmetric.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcho_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_factor\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \"\"\"\n\u001b[1;32m    154\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=False,\n\u001b[0;32m--> 155\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Common code for cholesky() and cho_factor().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         raise ValueError(\n\u001b[0;32m--> 499\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "class DataFrameCreator(object):\n",
    "    def __init__(self, stocks):\n",
    "        self.stocks = stocks\n",
    "\n",
    "    def __iter__(self):\n",
    "        # get the stocks first and iterate through them\n",
    "        for stock in self.stocks:\n",
    "            # get sentiment of articles for that day\n",
    "            date = stock.date\n",
    "            arts = Article.objects.filter(date_written=date)\n",
    "            if arts:\n",
    "                total_length = arts.aggregate(total_length=Sum('length'))['total_length']\n",
    "                smarter_sum = arts.aggregate(total_neg_words=Sum('smarter_negative_words'))['total_neg_words']\n",
    "                negative_sentiment = smarter_sum/total_length\n",
    "                yield {'date':date, 'sentiment':negative_sentiment, 'return': stock.log_return()}\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "def autocorrelate_data():\n",
    "    stocks = StockPrice.objects.all()\n",
    "    dfc = DataFrameCreator(stocks)\n",
    "    df = pd.DataFrame.from_dict(dfc)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    df = df[(df.T != 0).all()]\n",
    "    df  = df.set_index(['date'])\n",
    "    print(df.head())\n",
    "    arr = np.asarray(df)\n",
    "    print(arr)\n",
    "    # create the VAR model\n",
    "    model = VAR(endog=arr)\n",
    "    return model \n",
    "    \n",
    "model = autocorrelate_data()\n",
    "model_fit = model.fit(maxlags=10, ic='aic')\n",
    "plot = model_fit.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = model_fit.plot_forecast(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-405e2137a604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "type(plot)\n",
    "\n",
    "model_fit = model.fit(maxlags=5).summary()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date      value                line============] 100.0% ...Article 33196/33197\n",
      "0       2016-01-01   8.333333  Positive Sentiment\n",
      "1       2016-01-01  12.037037  Negative Sentiment\n",
      "2       2016-01-01   0.000000            GBPEUR=X\n",
      "3       2016-01-01   0.000000            GBPUSD=X\n",
      "4       2016-01-04  12.765957  Positive Sentiment\n",
      "...            ...        ...                 ...\n",
      "150294  2019-12-31  11.851852  Positive Sentiment\n",
      "150295  2019-12-31   5.185185  Negative Sentiment\n",
      "150296  2019-12-31  -0.256626                FTSE\n",
      "150297  2019-12-31  -0.004824            GBPEUR=X\n",
      "150298  2019-12-31  -0.011425            GBPUSD=X\n",
      "\n",
      "[150299 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from data_handler.preprocessing import produce_plots\n",
    "\n",
    "arts = Article.objects.all()\n",
    "df = produce_plots(arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['line']=='Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>date</th>\n",
       "      <th>line</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBPEUR=X</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Returns</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Returns</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBPUSD=X</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Returns</td>\n",
       "      <td>-0.006398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBPEUR=X</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Returns</td>\n",
       "      <td>-0.006398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FTSE</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Returns</td>\n",
       "      <td>-1.048494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       asset        date     line     value\n",
       "2   GBPEUR=X  2016-01-01  Returns  0.000000\n",
       "3   GBPUSD=X  2016-01-01  Returns  0.000000\n",
       "18  GBPUSD=X  2016-01-04  Returns -0.006398\n",
       "17  GBPEUR=X  2016-01-04  Returns -0.006398\n",
       "16      FTSE  2016-01-04  Returns -1.048494"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
