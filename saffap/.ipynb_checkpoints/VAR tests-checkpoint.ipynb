{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data_handler.models import Asset, Source\n",
    "from datetime import datetime\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "import pandas as pd\n",
    "from sentiment.models import Category, Label\n",
    "from sentiment.model import SentimentPriceModel\n",
    "import gensim\n",
    "from data_handler.helpers import progress\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTSE 250 Volume</th>\n",
       "      <th>ISEQ All Share Volume</th>\n",
       "      <th>Euro Stoxx 50 Return</th>\n",
       "      <th>Euro Stoxx 50 Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.846024</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>-3.632469</td>\n",
       "      <td>0.792579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-0.936379</td>\n",
       "      <td>-0.249442</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>-0.150276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.403054</td>\n",
       "      <td>-0.011577</td>\n",
       "      <td>-1.150151</td>\n",
       "      <td>0.503741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>-0.300610</td>\n",
       "      <td>0.617958</td>\n",
       "      <td>-1.703234</td>\n",
       "      <td>1.891533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>-0.864265</td>\n",
       "      <td>0.633654</td>\n",
       "      <td>-2.036661</td>\n",
       "      <td>0.878035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>-1.543409</td>\n",
       "      <td>-0.709089</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>-1.196817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>-2.746226</td>\n",
       "      <td>-0.926064</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-1.632069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>-1.817123</td>\n",
       "      <td>-0.851376</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>-1.118198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>-1.935581</td>\n",
       "      <td>-0.725604</td>\n",
       "      <td>-0.985013</td>\n",
       "      <td>-1.446346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-2.593621</td>\n",
       "      <td>-0.897785</td>\n",
       "      <td>-0.052283</td>\n",
       "      <td>-1.253218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FTSE 250 Volume  ISEQ All Share Volume  Euro Stoxx 50 Return  \\\n",
       "date                                                                       \n",
       "2016-01-04        -0.846024               0.016210             -3.632469   \n",
       "2016-01-05        -0.936379              -0.249442              0.168752   \n",
       "2016-01-06        -0.403054              -0.011577             -1.150151   \n",
       "2016-01-07        -0.300610               0.617958             -1.703234   \n",
       "2016-01-08        -0.864265               0.633654             -2.036661   \n",
       "...                     ...                    ...                   ...   \n",
       "2019-12-23        -1.543409              -0.709089              0.041056   \n",
       "2019-12-24        -2.746226              -0.926064              0.000513   \n",
       "2019-12-27        -1.817123              -0.851376              0.158570   \n",
       "2019-12-30        -1.935581              -0.725604             -0.985013   \n",
       "2019-12-31        -2.593621              -0.897785             -0.052283   \n",
       "\n",
       "            Euro Stoxx 50 Volume  \n",
       "date                              \n",
       "2016-01-04              0.792579  \n",
       "2016-01-05             -0.150276  \n",
       "2016-01-06              0.503741  \n",
       "2016-01-07              1.891533  \n",
       "2016-01-08              0.878035  \n",
       "...                          ...  \n",
       "2019-12-23             -1.196817  \n",
       "2019-12-24             -1.632069  \n",
       "2019-12-27             -1.118198  \n",
       "2019-12-30             -1.446346  \n",
       "2019-12-31             -1.253218  \n",
       "\n",
       "[1006 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assets\n",
    "spm = SentimentPriceModel()\n",
    "spm.add_asset_variable(asset=\"^FTMC\", column_name=\"FTSE 250\", zscore=True, volume=True, get_asset=False)\n",
    "spm.add_asset_variable(asset=\"^ISEQ\", column_name=\"ISEQ All Share\", zscore=True, volume=True, get_asset=False)\n",
    "spm.add_asset_variable(asset=\"^STOXX50E\", column_name=\"Euro Stoxx 50\", zscore=True, volume=True, get_asset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources\n",
    "uk_sources = list(Source.objects.filter(country=1).values_list('id', flat=True))\n",
    "irish_sources = list(Source.objects.filter(country=0).values_list('id', flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['market', 'economy', 'trade']\n",
      "Getting articles with market in their headline\n",
      "Getting articles with economy in their headline\n",
      "Getting articles with trade in their headline\n",
      "629\n",
      "<QuerySet [2]>\n",
      "Getting zscore===============================================] 100.0% ...2019-12-31\n",
      "Zscore of Financial Times (London, England) Negative\n",
      "['market', 'economy', 'trade']\n",
      "Getting articles with market in their headline\n",
      "Getting articles with economy in their headline\n",
      "Getting articles with trade in their headline\n",
      "408\n",
      "<QuerySet [4]>\n",
      "Getting zscore===============================================] 100.0% ...2019-12-31\n",
      "Zscore of The Times (London) Negative\n",
      "['market', 'economy', 'trade']\n",
      "Getting articles with market in their headline\n",
      "Getting articles with economy in their headline\n",
      "Getting articles with trade in their headline\n",
      "1407\n",
      "<QuerySet [6]>\n",
      "[=======================-------------------------------------] 39.0% ...2017-07-24\r"
     ]
    }
   ],
   "source": [
    "source_signals = 0\n",
    "for s in uk_sources:\n",
    "    sourcename=Source.objects.get(id=s).name\n",
    "    spm.add_sentiment_variable(column_name=\"{}\".format(sourcename), sentiwordnet=True, h_contents = [\"market\", \"economy\", \"trade\"], include_pos = False,source_filter=[s],set=True)\n",
    "if source_signals == 0:\n",
    "    df = spm.get_df()\n",
    "    df[\"UK Negative\"] = 0\n",
    "    for c in uk_sources:\n",
    "        sourcename=Source.objects.get(id=c).name\n",
    "        df[\"UK Negative\"] += df[\"{} Negative\".format(sourcename)]\n",
    "        df = df.drop([\"{} Negative\".format(sourcename)], axis=1)\n",
    "    spm.multivariate_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "4216\n",
      "Multiplying by weights: The Irish Times\n",
      "Getting zscore\n",
      "Zscore of The Irish Times\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d81724da1a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mirish_sources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msourcename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_sentiment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourcename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msource_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource_signals\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/saffap/sentiment/model.py\u001b[0m in \u001b[0;36madd_sentiment_variable\u001b[0;34m(self, left, category, set, zscore, column_name, source_filter, reset_df, sentiment_words, include_pos, sentiwordnet, h_contents, weighted, countries)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zscore of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                 \u001b[0msentiment_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mzscore\u001b[0;34m(a, axis, ddof, nan_policy)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0msstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m         \u001b[0mmns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m         \u001b[0msstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n\u001b[0;32m--> 154\u001b[0;31m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "source_signals = 0\n",
    "for s in irish_sources:\n",
    "    sourcename=Source.objects.get(id=s).name\n",
    "    spm.add_sentiment_variable(column_name=\"{}\".format(sourcename), category = cat, set=True, sentiment_words=list(expanded_list),  source_filter=[s], weighted=True, countries=True)\n",
    "if source_signals == 0:\n",
    "    df = spm.get_df()\n",
    "    df[\"Irish Negative\"] = 0\n",
    "    for c in irish_sources:\n",
    "        sourcename=Source.objects.get(id=c).name\n",
    "        df[\"Irish Negative\"] += df[\"{} Negativ\".format(sourcename)]\n",
    "        df = df.drop([\"{} Negativ\".format(sourcename)], axis=1)\n",
    "    spm.multivariate_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISEQ All Share Volume</th>\n",
       "      <th>Euro Stoxx 50 Volume</th>\n",
       "      <th>Word2Vec Irish Negativ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>0.617958</td>\n",
       "      <td>1.891533</td>\n",
       "      <td>-1.661334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>0.858023</td>\n",
       "      <td>1.313286</td>\n",
       "      <td>-1.938545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19</th>\n",
       "      <td>-0.005111</td>\n",
       "      <td>1.223274</td>\n",
       "      <td>-1.527699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25</th>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.758397</td>\n",
       "      <td>-1.861932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>0.338266</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>-1.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>-0.521523</td>\n",
       "      <td>-0.603189</td>\n",
       "      <td>-0.287799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>-0.615432</td>\n",
       "      <td>-0.481842</td>\n",
       "      <td>0.540923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>-0.240697</td>\n",
       "      <td>2.323367</td>\n",
       "      <td>-1.351681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>-0.851376</td>\n",
       "      <td>-1.118198</td>\n",
       "      <td>2.754284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>-0.725604</td>\n",
       "      <td>-1.446346</td>\n",
       "      <td>1.553148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISEQ All Share Volume  Euro Stoxx 50 Volume  \\\n",
       "date                                                      \n",
       "2016-01-07               0.617958              1.891533   \n",
       "2016-01-14               0.858023              1.313286   \n",
       "2016-01-19              -0.005111              1.223274   \n",
       "2016-01-25               0.102151              0.758397   \n",
       "2016-01-27               0.338266              0.617111   \n",
       "...                           ...                   ...   \n",
       "2019-12-18              -0.521523             -0.603189   \n",
       "2019-12-19              -0.615432             -0.481842   \n",
       "2019-12-20              -0.240697              2.323367   \n",
       "2019-12-27              -0.851376             -1.118198   \n",
       "2019-12-30              -0.725604             -1.446346   \n",
       "\n",
       "            Word2Vec Irish Negativ  \n",
       "date                                \n",
       "2016-01-07               -1.661334  \n",
       "2016-01-14               -1.938545  \n",
       "2016-01-19               -1.527699  \n",
       "2016-01-25               -1.861932  \n",
       "2016-01-27               -1.266667  \n",
       "...                            ...  \n",
       "2019-12-18               -0.287799  \n",
       "2019-12-19                0.540923  \n",
       "2019-12-20               -1.351681  \n",
       "2019-12-27                2.754284  \n",
       "2019-12-30                1.553148  \n",
       "\n",
       "[856 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.load_csv(\"w2v_vartest_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.multivariate_df.shape\n",
    "def adjust(val, length= 6): return str(val).ljust(length)\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def cointegration_test(df, key_col, alpha=0.05): \n",
    "    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n",
    "    out = coint_johansen(df,-1,5)\n",
    "    d = {'0.90':0, '0.95':1, '0.99':2}\n",
    "    traces = out.lr1\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    print('\\nName   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        if col == key_col:\n",
    "            print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTSE 100 Volume : 2.01\n",
      "ISEQ All Share Volume : 1.99\n",
      "Euro Stoxx 50 Volume : 2.01\n",
      "Word2Vec UK Negativ : 2.0\n",
      "\n",
      "Name   ::  Test Stat > C(95%)    =>   Signif  \n",
      " ----------------------------------------\n",
      "FTSE 100 Volume ::  203.78    > 40.1749   =>   True\n",
      "ISEQ All Share Volume ::  111.18    > 24.2761   =>   True\n",
      "Euro Stoxx 50 Volume ::  56.62     > 12.3212   =>   True\n",
      "Word2Vec UK Negativ ::  19.03     > 4.1296    =>   True\n"
     ]
    }
   ],
   "source": [
    "df = spm.multivariate_df\n",
    "from statsmodels.stats.stattools import durbin_watson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:218: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_table = spm.var().model.select_order(15).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>VAR Order Selection (* highlights the minimums)</caption>\n",
       "<tr>\n",
       "   <td></td>      <th>AIC</th>         <th>BIC</th>         <th>FPE</th>        <th>HQIC</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>  <td>    0.4389</td>  <td>    0.4596</td>  <td>     1.551</td>  <td>    0.4468</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>  <td>   -0.2798</td>  <td>   -0.1767*</td> <td>    0.7560</td>  <td>   -0.2405</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>  <td>   -0.3387</td>  <td>   -0.1532</td>  <td>    0.7127</td>  <td>   -0.2680</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>  <td>   -0.3778</td>  <td>   -0.1099</td>  <td>    0.6854</td>  <td>   -0.2757</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>  <td>   -0.4197</td>  <td>  -0.06940</td>  <td>    0.6573</td>  <td>   -0.2861*</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>  <td>   -0.4472*</td> <td>  -0.01455</td>  <td>    0.6394*</td> <td>   -0.2823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>  <td>   -0.4353</td>  <td>   0.07975</td>  <td>    0.6471</td>  <td>   -0.2390</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>  <td>   -0.4330</td>  <td>    0.1645</td>  <td>    0.6486</td>  <td>   -0.2052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>  <td>   -0.4312</td>  <td>    0.2487</td>  <td>    0.6498</td>  <td>   -0.1720</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>  <td>   -0.4111</td>  <td>    0.3512</td>  <td>    0.6630</td>  <td>   -0.1206</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th> <td>   -0.4296</td>  <td>    0.4152</td>  <td>    0.6509</td>  <td>   -0.1076</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th> <td>   -0.4117</td>  <td>    0.5155</td>  <td>    0.6627</td>  <td>  -0.05826</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th> <td>   -0.3946</td>  <td>    0.6149</td>  <td>    0.6742</td>  <td> -0.009795</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th> <td>   -0.3727</td>  <td>    0.7193</td>  <td>    0.6892</td>  <td>   0.04359</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th> <td>   -0.3545</td>  <td>    0.8199</td>  <td>    0.7020</td>  <td>   0.09321</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th> <td>   -0.3415</td>  <td>    0.9154</td>  <td>    0.7113</td>  <td>    0.1376</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:218: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "maxlag should be < nobs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d73190185f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcointegration_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eq_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-791fe8d0b132>\u001b[0m in \u001b[0;36mcointegration_test\u001b[0;34m(df, key_col, alpha)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcointegration_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoint_johansen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'0.90'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.95'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.99'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/vecm.py\u001b[0m in \u001b[0;36mcoint_johansen\u001b[0;34m(endog, det_order, k_ar_diff)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetrend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_ar_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_ar_diff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetrend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final year project/sentiment_analysis/lib/python3.6/site-packages/statsmodels/tsa/tsatools.py\u001b[0m in \u001b[0;36mlagmat\u001b[0;34m(x, maxlag, trim, original, use_pandas)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mdropidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maxlag should be < nobs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: maxlag should be < nobs"
     ]
    }
   ],
   "source": [
    "key_col = 'Word2Vec UK Negativ'\n",
    "df = pd.DataFrame()\n",
    "spm2 = SentimentPriceModel()\n",
    "mv = spm.get_df()\n",
    "cols = mv.columns  \n",
    "acc_df = pd.DataFrame()\n",
    "acc_df[key_col] = mv[key_col]\n",
    "acc_df.set_index(mv.index)\n",
    "counter = 0\n",
    "stop = 6\n",
    "lag = 5\n",
    "for col in cols:\n",
    "    if col == key_col:\n",
    "        continue\n",
    "    model = \"Model {}\".format(counter)\n",
    "    acc_df[col] = mv[col]\n",
    "    spm2.set_df(acc_df)\n",
    "    var = spm2.var()\n",
    "    fit = var.model.fit(lag)\n",
    "    index = fit.get_eq_index(key_col)\n",
    "    df_out = pd.DataFrame(columns = [model])\n",
    "    lookup = {}\n",
    "    out = durbin_watson(fit.resid)\n",
    "\n",
    "    for col, val in zip(df_out.columns, out):\n",
    "        if col == key_col:\n",
    "            print(adjust(col), ':', round(val, 2))\n",
    "    # cointegration_test(df, key_col)\n",
    "    for name in fit.names:\n",
    "        j = fit.get_eq_index(name)\n",
    "        lookup[j] = name\n",
    "\n",
    "    for i in range(len(fit.coefs[0])):\n",
    "        row = lookup[i]\n",
    "        for j in range(len(fit.coefs)):\n",
    "            t = j+1\n",
    "            row_name = \"{} t-{}\".format(row, t)\n",
    "            pval = fit.pvalues[key_col][\"L{}.{}\".format(t, row)]\n",
    "            res = \"\"\n",
    "            if pval <= 0.10 and pval > 0.05:\n",
    "                res = \"{:.4f}*\".format(fit.coefs[j][index][i])\n",
    "            elif pval <= 0.05 and pval > 0.01:\n",
    "                res = \"{:.4f}**\".format(fit.coefs[j][index][i])\n",
    "            elif pval <= 0.01:\n",
    "                res = \"{:.4f}***\".format(fit.coefs[j][index][i])\n",
    "            else:\n",
    "                res = fit.coefs[j][index][i]\n",
    "            df_out.loc[row_name] = res\n",
    "    df = pd.concat([df, df_out], axis=1, sort=False)\n",
    "    counter += 1\n",
    "    if counter == stop:\n",
    "        print(fit.summary())\n",
    "        break\n",
    "df = df.fillna(\"-\")\n",
    "df = df.replace()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Granger causality F-test. H_0: Word2Vec Irish Negativ does not Granger-cause ISEQ All Share Volume. Conclusion: fail to reject H_0 at 5% significance level.</caption>\n",
       "<tr>\n",
       "  <th>Test statistic</th> <th>Critical value</th> <th>p-value</th>    <th>df</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>1.070</td>          <td>2.013</td>      <td>0.380</td>  <td>(7, 2481)</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = fit.test_causality(\"ISEQ All Share Volume\", \"Word2Vec Irish Negativ\", )\n",
    "h1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTSE 100 Volume</th>\n",
       "      <th>ISEQ All Share Volume</th>\n",
       "      <th>Euro Stoxx 50 Volume</th>\n",
       "      <th>Word2Vec UK Negativ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>0.368897</td>\n",
       "      <td>0.338266</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>-2.767022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28</th>\n",
       "      <td>0.444651</td>\n",
       "      <td>0.771961</td>\n",
       "      <td>1.857351</td>\n",
       "      <td>-3.264444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-15</th>\n",
       "      <td>-0.285359</td>\n",
       "      <td>1.055438</td>\n",
       "      <td>1.819181</td>\n",
       "      <td>-1.742727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-19</th>\n",
       "      <td>-0.423521</td>\n",
       "      <td>1.931092</td>\n",
       "      <td>1.345190</td>\n",
       "      <td>-2.944776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-22</th>\n",
       "      <td>0.138648</td>\n",
       "      <td>2.633814</td>\n",
       "      <td>0.353910</td>\n",
       "      <td>3.980155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>1.332587</td>\n",
       "      <td>-0.571294</td>\n",
       "      <td>-0.389551</td>\n",
       "      <td>-0.390759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>-0.482754</td>\n",
       "      <td>-0.521523</td>\n",
       "      <td>-0.603189</td>\n",
       "      <td>-1.120399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>-0.558263</td>\n",
       "      <td>-0.615432</td>\n",
       "      <td>-0.481842</td>\n",
       "      <td>-2.086874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>1.607607</td>\n",
       "      <td>-0.240697</td>\n",
       "      <td>2.323367</td>\n",
       "      <td>0.388803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>-2.084650</td>\n",
       "      <td>-0.851376</td>\n",
       "      <td>-1.118198</td>\n",
       "      <td>-1.899245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FTSE 100 Volume  ISEQ All Share Volume  Euro Stoxx 50 Volume  \\\n",
       "date                                                                       \n",
       "2016-01-27         0.368897               0.338266              0.617111   \n",
       "2016-01-28         0.444651               0.771961              1.857351   \n",
       "2016-02-15        -0.285359               1.055438              1.819181   \n",
       "2016-02-19        -0.423521               1.931092              1.345190   \n",
       "2016-02-22         0.138648               2.633814              0.353910   \n",
       "...                     ...                    ...                   ...   \n",
       "2019-12-17         1.332587              -0.571294             -0.389551   \n",
       "2019-12-18        -0.482754              -0.521523             -0.603189   \n",
       "2019-12-19        -0.558263              -0.615432             -0.481842   \n",
       "2019-12-20         1.607607              -0.240697              2.323367   \n",
       "2019-12-27        -2.084650              -0.851376             -1.118198   \n",
       "\n",
       "            Word2Vec UK Negativ  \n",
       "date                             \n",
       "2016-01-27            -2.767022  \n",
       "2016-01-28            -3.264444  \n",
       "2016-02-15            -1.742727  \n",
       "2016-02-19            -2.944776  \n",
       "2016-02-22             3.980155  \n",
       "...                         ...  \n",
       "2019-12-17            -0.390759  \n",
       "2019-12-18            -1.120399  \n",
       "2019-12-19            -2.086874  \n",
       "2019-12-20             0.388803  \n",
       "2019-12-27            -1.899245  \n",
       "\n",
       "[821 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm = SentimentPriceModel()\n",
    "spm.load_csv(\"w2v_vartest_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:49:51: loading Word2Vec object from word2vec.model\n",
      "INFO - 21:49:51: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 21:49:51: setting ignored attribute vectors_norm to None\n",
      "INFO - 21:49:51: loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "INFO - 21:49:51: loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "INFO - 21:49:51: setting ignored attribute cum_table to None\n",
      "INFO - 21:49:51: loaded word2vec.model\n"
     ]
    }
   ],
   "source": [
    "word2vec = gensim.models.Word2Vec.load(\"word2vec.model\")\n",
    "vectors = word2vec.wv\n",
    "cat = \"Negativ\"\n",
    "sw = stopwords.words('english')\n",
    "topn=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:49:55: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...Word not added. \"word 'yelp' not in vocabulary\"y\"lary\"\"y\"\r"
     ]
    }
   ],
   "source": [
    "cat = \"Negativ\"\n",
    "words = [w.lower() for w in Category.objects.get(name=cat).words.all().values_list('word', flat=True)]\n",
    "expanded_list = set()\n",
    "index = 0\n",
    "length = len(words)\n",
    "for w in words:\n",
    "    index +=1\n",
    "    try:\n",
    "        if w in sw:\n",
    "            continue\n",
    "        werds = [x for (x,_) in vectors.most_similar(positive=w, topn=topn)]\n",
    "        for x in werds:\n",
    "            expanded_list.add(x)\n",
    "            progress(index, length, status=\"Added word\")\n",
    "         \n",
    "    except Exception as e:\n",
    "        progress(index, length, status=\"Word not added. {}\".format(e))\n",
    "    expanded_list.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shameful',\n",
       " 'severity',\n",
       " 'feature',\n",
       " 'costly',\n",
       " 'jeopardy',\n",
       " 'arrest',\n",
       " 'odd',\n",
       " 'horrible',\n",
       " 'narcissist',\n",
       " 'condemnation',\n",
       " 'reich',\n",
       " 'disproportionately',\n",
       " 'pigeon',\n",
       " 'jumpy',\n",
       " 'agile',\n",
       " 'worse',\n",
       " 'chiefly',\n",
       " 'humiliation',\n",
       " 'pessimistic',\n",
       " 'deflect',\n",
       " 'exile',\n",
       " 'unfair',\n",
       " 'deceptive',\n",
       " 'murderous',\n",
       " 'retire',\n",
       " 'furnace',\n",
       " 'disarm',\n",
       " 'demand',\n",
       " 'vacillation',\n",
       " 'lost',\n",
       " 'questionable',\n",
       " 'britpop',\n",
       " 'casualty',\n",
       " 'pollutant',\n",
       " 'fatigue',\n",
       " 'exempt',\n",
       " 'bombast',\n",
       " 'allege',\n",
       " 'slap',\n",
       " 'shred',\n",
       " 'invade',\n",
       " 'clamorous',\n",
       " 'controversial',\n",
       " 'tutorial',\n",
       " 'shamble',\n",
       " 'belie',\n",
       " 'languish',\n",
       " 'front',\n",
       " 'destroy',\n",
       " 'profess',\n",
       " 'independence',\n",
       " 'suez',\n",
       " 'lonely',\n",
       " 'alienate',\n",
       " 'egregious',\n",
       " 'disclaim',\n",
       " 'disregard',\n",
       " 'esoteric',\n",
       " 'context',\n",
       " 'dissention',\n",
       " 'aggression',\n",
       " 'mess',\n",
       " 'fire',\n",
       " 'tedious',\n",
       " 'backstabbing',\n",
       " 'administrative_burden',\n",
       " 'deviation',\n",
       " 'primitive',\n",
       " 'aghast',\n",
       " 'counteract',\n",
       " 'chore',\n",
       " 'chide',\n",
       " 'allegation',\n",
       " 'thud',\n",
       " 'bite',\n",
       " 'illiterate',\n",
       " 'erase',\n",
       " 'chastise',\n",
       " 'reality',\n",
       " 'resentment',\n",
       " 'temper',\n",
       " 'pandemonium',\n",
       " 'press',\n",
       " 'deceitful',\n",
       " 'peril',\n",
       " 'dominance',\n",
       " 'complainant',\n",
       " 'cpi',\n",
       " 'menial',\n",
       " 'misery',\n",
       " 'tragic',\n",
       " 'contentious',\n",
       " 'brawl',\n",
       " 'realise',\n",
       " 'prohibitive',\n",
       " 'distracting',\n",
       " 'onstage',\n",
       " 'arthritis',\n",
       " 'capsize',\n",
       " 'accept',\n",
       " 'tariff',\n",
       " 'argument',\n",
       " 'weasel',\n",
       " 'reoffend',\n",
       " 'rant',\n",
       " 'apprehension',\n",
       " 'servitude',\n",
       " 'rampage',\n",
       " 'ecstatic',\n",
       " 'dissatisfaction',\n",
       " 'futility',\n",
       " 'intervention',\n",
       " 'ridicule',\n",
       " 'murderer',\n",
       " 'rubbish',\n",
       " 'wretchedness',\n",
       " 'discomfort',\n",
       " 'suppression',\n",
       " 'scold',\n",
       " 'ccpc',\n",
       " 'sweat',\n",
       " 'mouse',\n",
       " 'divert',\n",
       " 'unsteady',\n",
       " 'irrational',\n",
       " 'populace',\n",
       " 'bottleneck',\n",
       " 'dispel',\n",
       " 'lowly',\n",
       " 'investigation',\n",
       " 'elderly',\n",
       " 'surrender',\n",
       " 'stormy',\n",
       " 'deception',\n",
       " 'snarl',\n",
       " 'anomalous',\n",
       " 'truce',\n",
       " 'lie',\n",
       " 'dumb',\n",
       " 'loser',\n",
       " 'rude',\n",
       " 'subversion',\n",
       " 'negligent',\n",
       " 'distort',\n",
       " 'incompatibility',\n",
       " 'downturn',\n",
       " 'vagabond',\n",
       " 'imprecise',\n",
       " 'affectation',\n",
       " 'blindness',\n",
       " 'unfit',\n",
       " 'uninspiring',\n",
       " 'nervous',\n",
       " 'thunder',\n",
       " 'abdication',\n",
       " 'decompose',\n",
       " 'verbally',\n",
       " 'pummel',\n",
       " 'unbelievable',\n",
       " 'irk',\n",
       " 'daze',\n",
       " 'jail',\n",
       " 'capitalise',\n",
       " 'roundabout',\n",
       " 'implicate',\n",
       " 'monger',\n",
       " 'conceit',\n",
       " 'slanderer',\n",
       " 'aggravate',\n",
       " 'imperialism',\n",
       " 'prolong',\n",
       " 'trap',\n",
       " 'outbreak',\n",
       " 'excommunication',\n",
       " 'corbynista',\n",
       " 'infiltration',\n",
       " 'unequal',\n",
       " 'jog',\n",
       " 'hot',\n",
       " 'deplete',\n",
       " 'muddy',\n",
       " 'come',\n",
       " 'deficient',\n",
       " 'shock',\n",
       " 'serial',\n",
       " 'exasperate',\n",
       " 'err',\n",
       " 'drab',\n",
       " 'nonchalant',\n",
       " 'barrier',\n",
       " 'nervousness',\n",
       " 'mistrust',\n",
       " 'threat',\n",
       " 'vehemently',\n",
       " 'ungrateful',\n",
       " 'plot',\n",
       " 'cramp',\n",
       " 'adversary',\n",
       " 'helpless',\n",
       " 'diabolic',\n",
       " 'greyhound',\n",
       " 'lethal',\n",
       " 'weariness',\n",
       " 'decline',\n",
       " 'dispute',\n",
       " 'dictatorial',\n",
       " 'calamity',\n",
       " 'contaminate',\n",
       " 'grapple',\n",
       " 'borderline',\n",
       " 'ail',\n",
       " 'cripple',\n",
       " 'hell',\n",
       " 'plastic',\n",
       " 'squall',\n",
       " 'curtain',\n",
       " 'fussy',\n",
       " 'debatable',\n",
       " 'weave',\n",
       " 'minefield',\n",
       " 'flaw',\n",
       " 'misunderstood',\n",
       " 'lawless',\n",
       " 'burglary',\n",
       " 'condemn',\n",
       " 'confess',\n",
       " 'headache',\n",
       " 'chemical_weapon',\n",
       " 'tramp',\n",
       " 'senile',\n",
       " 'domination',\n",
       " 'fest',\n",
       " 'ghetto',\n",
       " 'consent',\n",
       " 'warning',\n",
       " 'demon',\n",
       " 'conspire',\n",
       " 'battlefield',\n",
       " 'ghost',\n",
       " 'repeatedly',\n",
       " 'facilitate',\n",
       " 'yearn',\n",
       " 'spite',\n",
       " 'melodrama',\n",
       " 'grim',\n",
       " 'payment',\n",
       " 'sabotage',\n",
       " 'terror',\n",
       " 'anger',\n",
       " 'seize',\n",
       " 'bore',\n",
       " 'marginal',\n",
       " 'howl',\n",
       " 'pretend',\n",
       " 'broken-hearted',\n",
       " 'homosexuality',\n",
       " 'sunder',\n",
       " 'stamp',\n",
       " 'ferocity',\n",
       " 'mayfair',\n",
       " 'swine',\n",
       " 'disgraceful',\n",
       " 'shrill',\n",
       " 'thorny',\n",
       " 'vengeance',\n",
       " 'expensive',\n",
       " 'shallow',\n",
       " 'hysteria',\n",
       " 'illegality',\n",
       " 'race',\n",
       " 'impulsive',\n",
       " 'unreliability',\n",
       " 'assassinate',\n",
       " 'angry',\n",
       " 'conspirator',\n",
       " 'resend',\n",
       " 'uprising',\n",
       " 'superstition',\n",
       " 'amid',\n",
       " 'impatience',\n",
       " 'discordant',\n",
       " 'sanity',\n",
       " 'underworld',\n",
       " 'back',\n",
       " 'childish',\n",
       " 'strap',\n",
       " 'vice',\n",
       " 'strangle',\n",
       " 'ideologues',\n",
       " 'tension',\n",
       " 'sufferer',\n",
       " 'upheaval',\n",
       " 'hat',\n",
       " 'serve',\n",
       " 'destitute',\n",
       " 'downhearted',\n",
       " 'powerless',\n",
       " 'heartbreaking',\n",
       " 'unaccustomed',\n",
       " 'raid',\n",
       " 'perish',\n",
       " 'feign',\n",
       " 'precarious',\n",
       " 'antitrust',\n",
       " 'atrocious',\n",
       " 'iron',\n",
       " 'nullification',\n",
       " 'unworthy',\n",
       " 'feudal',\n",
       " 'madness',\n",
       " 'downbeat',\n",
       " 'unnecessary',\n",
       " 'rivalry',\n",
       " 'tax_avoidance',\n",
       " 'defensive',\n",
       " 'calais',\n",
       " 'salisbury',\n",
       " 'ailment',\n",
       " 'bury',\n",
       " 'neutralize',\n",
       " 'barbarous',\n",
       " 'dissipate',\n",
       " 'nag',\n",
       " 'loom',\n",
       " 'atrophy',\n",
       " 'myth',\n",
       " 'stalemate',\n",
       " 'hoot',\n",
       " 'invisible_border',\n",
       " 'falsehood',\n",
       " 'degrade',\n",
       " 'brilliance',\n",
       " 'mortify',\n",
       " 'rival',\n",
       " 'severe',\n",
       " 'competitive',\n",
       " 'remoaner',\n",
       " 'delinquent',\n",
       " 'weirdly',\n",
       " 'inhumane',\n",
       " 'terrible',\n",
       " 'overflow',\n",
       " 'waterloo',\n",
       " 'instable',\n",
       " 'transfix',\n",
       " 'haunt',\n",
       " 'suspicious',\n",
       " 'fickle',\n",
       " 'witless',\n",
       " 'distraction',\n",
       " 'fraught',\n",
       " 'immorality',\n",
       " 'counteraction',\n",
       " 'slight',\n",
       " 'environmental_standard',\n",
       " 'mean',\n",
       " 'scepticism',\n",
       " 'obstruction',\n",
       " 'obstacle',\n",
       " 'rumple',\n",
       " 'dubious',\n",
       " 'worrier',\n",
       " 'sprain',\n",
       " 'police',\n",
       " 'skill_shortage',\n",
       " 'snore',\n",
       " 'lehman',\n",
       " 'gaddafi',\n",
       " 'cost',\n",
       " 'devaluation',\n",
       " 'mindless',\n",
       " 'oversight',\n",
       " 'lib',\n",
       " 'scrap',\n",
       " 'twitch',\n",
       " 'brandish',\n",
       " 'vomit',\n",
       " 'broker',\n",
       " 'dispense',\n",
       " 'hard',\n",
       " 'liable',\n",
       " 'disabuse',\n",
       " 'unseasonably',\n",
       " 'stringent',\n",
       " 'wrath',\n",
       " 'polemic',\n",
       " 'enemy',\n",
       " 'tackle',\n",
       " 'insolvency',\n",
       " 'cybercrime',\n",
       " 'incapable',\n",
       " 'feud',\n",
       " 'sexually',\n",
       " 'brazen',\n",
       " 'compatibility',\n",
       " 'bitter',\n",
       " 'ambiguity',\n",
       " 'urgent',\n",
       " 'vehement',\n",
       " 'despise',\n",
       " 'denounce',\n",
       " 'prohibit',\n",
       " 'darkness',\n",
       " 'unviable',\n",
       " 'scare',\n",
       " 'rebuff',\n",
       " 'mine',\n",
       " 'pervade',\n",
       " 'avalanche',\n",
       " 'righteous',\n",
       " 'piece',\n",
       " 'extravagant',\n",
       " 'gruff',\n",
       " 'sketchy',\n",
       " 'lame',\n",
       " 'demonise',\n",
       " 'smash',\n",
       " 'clash',\n",
       " 'beseech',\n",
       " 'annoy',\n",
       " 'smear',\n",
       " 'spear',\n",
       " 'wayward',\n",
       " 'disapproval',\n",
       " 'wear',\n",
       " 'weird',\n",
       " 'archaic',\n",
       " 'politicking',\n",
       " 'scrub',\n",
       " 'unpalatable',\n",
       " 'outrage',\n",
       " 'needle',\n",
       " 'pollute',\n",
       " 'pelt',\n",
       " 'veg',\n",
       " 'bleak',\n",
       " 'puny',\n",
       " 'deplorable',\n",
       " 'nature',\n",
       " 'sore',\n",
       " 'bp',\n",
       " 'flee',\n",
       " 'gullible',\n",
       " 'dante',\n",
       " 'player',\n",
       " 'depraved',\n",
       " 'sucker',\n",
       " 'alienation',\n",
       " 'inundate',\n",
       " 'hunter',\n",
       " 'limitation',\n",
       " 'meltdown',\n",
       " 'estranged',\n",
       " 'forgiveness',\n",
       " 'insecurity',\n",
       " 'avoid_cliff',\n",
       " 'cynic',\n",
       " 'humiliate',\n",
       " 'blockhead',\n",
       " 'unexpectedly',\n",
       " 'cold',\n",
       " 'flounder',\n",
       " 'antipathy',\n",
       " 'depose',\n",
       " 'juggle',\n",
       " 'botch',\n",
       " 'battle',\n",
       " 'vogel',\n",
       " 'dissent',\n",
       " 'unfairly',\n",
       " 'preferential',\n",
       " 'coarseness',\n",
       " 'shell',\n",
       " 'subtract',\n",
       " 'bolt',\n",
       " 'circle',\n",
       " 'liu',\n",
       " 'nige',\n",
       " 'fabrication',\n",
       " 'tory_rebel',\n",
       " 'subjugation',\n",
       " 'haiti',\n",
       " 'vie',\n",
       " 'suspicion',\n",
       " 'interrupt',\n",
       " 'require',\n",
       " 'predicament',\n",
       " 'accident',\n",
       " 'recuse',\n",
       " 'hit',\n",
       " 'unload',\n",
       " 'derision',\n",
       " 'novice',\n",
       " 'mental',\n",
       " 'exception',\n",
       " 'toxic',\n",
       " 'struck',\n",
       " 'coolness',\n",
       " 'sorrowful',\n",
       " 'sputter',\n",
       " 'millennium',\n",
       " 'transpose',\n",
       " 'frigid',\n",
       " 'mourn',\n",
       " 'excess',\n",
       " 'crumple',\n",
       " 'aesthetic',\n",
       " 'belligerence',\n",
       " 'neurotic',\n",
       " 'lull',\n",
       " 'rig',\n",
       " 'appoint',\n",
       " 'conflict',\n",
       " 'banish',\n",
       " 'asunder',\n",
       " 'know',\n",
       " 'erosion',\n",
       " 'exploitative',\n",
       " 'recover',\n",
       " 'bound',\n",
       " 'fruitless',\n",
       " 'overturn',\n",
       " 'deplore',\n",
       " 'box',\n",
       " 'cancellation',\n",
       " 'commotion',\n",
       " 'filthy',\n",
       " 'desolate',\n",
       " 'hurt',\n",
       " 'blemish',\n",
       " 'weimar',\n",
       " 'intimidate',\n",
       " 'slander',\n",
       " 'erroneous',\n",
       " 'redundancy',\n",
       " 'forsake',\n",
       " 'sleeper',\n",
       " 'chaotic',\n",
       " 'settle',\n",
       " 'stagnant',\n",
       " 'myanmar',\n",
       " 'oppress',\n",
       " 'nuclear_deterrent',\n",
       " 'imprison',\n",
       " 'scum',\n",
       " 'loveless',\n",
       " 'devoid',\n",
       " 'approve',\n",
       " 'hellbent',\n",
       " 'mishap',\n",
       " 'sedentary',\n",
       " 'jar',\n",
       " 'retard',\n",
       " 'sap',\n",
       " 'faintly',\n",
       " 'rebellious',\n",
       " 'trouble',\n",
       " 'bomber',\n",
       " 'anarchy',\n",
       " 'impediment',\n",
       " 'disillusion',\n",
       " 'incomprehension',\n",
       " 'pitiful',\n",
       " 'procrastination',\n",
       " 'retreat',\n",
       " 'rack',\n",
       " 'unsettling',\n",
       " 'wicked',\n",
       " 'inflict',\n",
       " 'scandalous',\n",
       " 'oath',\n",
       " 'slayer',\n",
       " 'delusion',\n",
       " 'punish',\n",
       " 'humour',\n",
       " 'stagnate',\n",
       " 'disturb',\n",
       " 'mention',\n",
       " 'subvention',\n",
       " 'negligence',\n",
       " 'will',\n",
       " 'confound',\n",
       " 'subvert',\n",
       " 'tumultuous',\n",
       " 'conformity',\n",
       " 'intemperate',\n",
       " 'expose',\n",
       " 'lone',\n",
       " 'oust',\n",
       " 'pinch',\n",
       " 'unbearable',\n",
       " 'venomous',\n",
       " 'motionless',\n",
       " 'unfortunate',\n",
       " 'venom',\n",
       " 'probe',\n",
       " 'cynical',\n",
       " 'devastation',\n",
       " 'impetuous',\n",
       " 'inflame',\n",
       " 'disavow',\n",
       " 'oppressive',\n",
       " 'punch',\n",
       " 'descend',\n",
       " 'retaliate',\n",
       " 'stupidity',\n",
       " 'artificial',\n",
       " 'condescending',\n",
       " 'blind',\n",
       " 'epidemic',\n",
       " 'stasis',\n",
       " 'reluctantly',\n",
       " 'poor',\n",
       " 'wrestle',\n",
       " 'adolescent',\n",
       " 'totalitarian',\n",
       " 'yawn',\n",
       " 'selfemployed',\n",
       " 'resignation',\n",
       " 'tire',\n",
       " 'sorrow',\n",
       " 'transgress',\n",
       " 'unfeeling',\n",
       " 'discharge',\n",
       " 'killer',\n",
       " 'misuse',\n",
       " 'thwart',\n",
       " 'infuriate',\n",
       " 'stain',\n",
       " 'diva',\n",
       " 'offence',\n",
       " 'vanish',\n",
       " 'blah',\n",
       " 'misfortune',\n",
       " 'alitalia',\n",
       " 'untrained',\n",
       " 'peddle',\n",
       " 'wrought',\n",
       " 'encroachment',\n",
       " 'indefinite',\n",
       " 'sympathy',\n",
       " 'useless',\n",
       " 'skier',\n",
       " 'gloat',\n",
       " 'envelop',\n",
       " 'doll',\n",
       " 'deadweight',\n",
       " 'disruption',\n",
       " 'unhappy',\n",
       " 'outsider',\n",
       " 'jockey',\n",
       " 'rage',\n",
       " 'fool',\n",
       " 'famished',\n",
       " 'feeble',\n",
       " 'dismiss',\n",
       " 'corruption',\n",
       " 'antagonism',\n",
       " 'darn',\n",
       " 'perverse',\n",
       " 'vol',\n",
       " 'covet',\n",
       " 'inferior',\n",
       " 'wish',\n",
       " 'powerlessness',\n",
       " 'lag',\n",
       " 'undue',\n",
       " 'hoard',\n",
       " 'haughty',\n",
       " 'wonder',\n",
       " 'endanger',\n",
       " 'disinformation',\n",
       " 'dread',\n",
       " 'treasonous',\n",
       " 'controversy',\n",
       " 'discriminate',\n",
       " 'study',\n",
       " 'revolution',\n",
       " 'cannon',\n",
       " 'aggressive',\n",
       " 'catch',\n",
       " 'forgetfulness',\n",
       " 'combatant',\n",
       " 'meek',\n",
       " 'jeopardize',\n",
       " 'overthrow',\n",
       " 'crime',\n",
       " 'leakage',\n",
       " 'sober',\n",
       " 'swell',\n",
       " 'discontent',\n",
       " 'slam',\n",
       " 'credulous',\n",
       " 'scary',\n",
       " 'hassle',\n",
       " 'reflective',\n",
       " 'earth',\n",
       " 'ambiguous',\n",
       " 'bruise',\n",
       " 'repulsive',\n",
       " 'despair',\n",
       " 'rip',\n",
       " 'ultimatum',\n",
       " 'wallow',\n",
       " 'chaos',\n",
       " 'annoyance',\n",
       " 'inappropriate',\n",
       " 'sentence',\n",
       " 'formidable',\n",
       " 'incorrect',\n",
       " 'seller',\n",
       " 'sequester',\n",
       " 'sullen',\n",
       " 'bellow',\n",
       " 'fight',\n",
       " 'utterance',\n",
       " 'horrific',\n",
       " 'enrage',\n",
       " 'agonize',\n",
       " 'juggernaut',\n",
       " 'lack_progress',\n",
       " 'monarchy',\n",
       " 'obsolete',\n",
       " 'disgust',\n",
       " 'hostile',\n",
       " 'rigid',\n",
       " 'haphazard',\n",
       " 'bang',\n",
       " 'satisfy',\n",
       " 'kidnap',\n",
       " 'overrun',\n",
       " 'prop',\n",
       " 'recent',\n",
       " 'snigger',\n",
       " 'edge',\n",
       " 'muddle',\n",
       " 'transcript',\n",
       " 'arbitrate',\n",
       " 'villain',\n",
       " 'anaemic',\n",
       " 'catastrophe',\n",
       " 'idiotic',\n",
       " 'regression',\n",
       " 'uneasiness',\n",
       " 'idleness',\n",
       " 'innate',\n",
       " 'clog',\n",
       " 'exclamation',\n",
       " 'dustbin',\n",
       " 'restive',\n",
       " 'christians',\n",
       " 'awkward',\n",
       " 'accuse',\n",
       " 'co_founder',\n",
       " 'fret',\n",
       " 'animate',\n",
       " 'exploit',\n",
       " 'invalid',\n",
       " 'theoretical',\n",
       " 'null',\n",
       " 'paranoid',\n",
       " 'prediction',\n",
       " 'refrigerate',\n",
       " 'heckle',\n",
       " 'storm',\n",
       " 'inflation',\n",
       " 'prosecutor',\n",
       " 'winner',\n",
       " 'absent',\n",
       " 'tote',\n",
       " 'contempt',\n",
       " 'lose',\n",
       " 'recalcitrant',\n",
       " 'weigh',\n",
       " 'forbidden',\n",
       " 'expense',\n",
       " 'shame',\n",
       " 'short',\n",
       " 'priest',\n",
       " 'deaf',\n",
       " 'detrimental',\n",
       " 'entreat',\n",
       " 'jihadi',\n",
       " 'abscond',\n",
       " 'shove',\n",
       " 'enslave',\n",
       " 'shortage',\n",
       " 'constrain',\n",
       " 'dreary',\n",
       " 'eurocent',\n",
       " 'discrepant',\n",
       " 'fade',\n",
       " 'crossfire',\n",
       " 'blame',\n",
       " 'drought',\n",
       " 'impersonal',\n",
       " 'resentful',\n",
       " 'exclude',\n",
       " 'wtf',\n",
       " 'wrong',\n",
       " 'ineffectiveness',\n",
       " 'infringement',\n",
       " 'diabolical',\n",
       " 'rash',\n",
       " 'scared',\n",
       " 'hunger',\n",
       " 'anxiety',\n",
       " 'cumbersome',\n",
       " 'deadly',\n",
       " 'jobless_rate',\n",
       " 'greed',\n",
       " 'tie',\n",
       " 'provoke',\n",
       " 'touchy',\n",
       " 'inconvenient',\n",
       " 'absorber',\n",
       " 'barren',\n",
       " 'lower',\n",
       " 'pessimism',\n",
       " 'fear',\n",
       " 'dreamy',\n",
       " 'dissolve',\n",
       " 'shameless',\n",
       " 'suppress',\n",
       " 'heartily',\n",
       " 'heretic',\n",
       " 'astray',\n",
       " 'irresistible',\n",
       " 'explode',\n",
       " 'disenfranchise',\n",
       " 'forbid',\n",
       " 'reactive',\n",
       " 'ride',\n",
       " 'adherent',\n",
       " 'ruin',\n",
       " 'despite',\n",
       " 'newman',\n",
       " 'shambolic',\n",
       " 'adultery',\n",
       " 'europhobes',\n",
       " 'pub',\n",
       " 'disturbance',\n",
       " 'insinuate',\n",
       " 'interference',\n",
       " 'betray',\n",
       " 'rattle',\n",
       " 'involve',\n",
       " 'taboo',\n",
       " 'prowl',\n",
       " 'damned',\n",
       " 'shriek',\n",
       " 'malignant',\n",
       " 'unforgiving',\n",
       " 'disrupt',\n",
       " 'trudge',\n",
       " 'apathy',\n",
       " 'whimsy',\n",
       " 'inevitable',\n",
       " 'indecent',\n",
       " 'disagreeable',\n",
       " 'autocrat',\n",
       " 'savage',\n",
       " 'entitlement',\n",
       " 'pensioner',\n",
       " 'refusal',\n",
       " 'social_medium',\n",
       " 'disastrous',\n",
       " 'disbelief',\n",
       " 'superficial',\n",
       " 'harm',\n",
       " 'mist',\n",
       " 'drummer',\n",
       " 'boastful',\n",
       " 'impure',\n",
       " 'vexation',\n",
       " 'idiot',\n",
       " 'devalue',\n",
       " 'deceive',\n",
       " 'departure',\n",
       " 'kill',\n",
       " 'insolence',\n",
       " 'boldness',\n",
       " 'wvr',\n",
       " 'autocratic',\n",
       " 'gunmen',\n",
       " 'repudiate',\n",
       " 'irregularity',\n",
       " 'dement',\n",
       " 'pm',\n",
       " 'blow',\n",
       " 'commonplace',\n",
       " 'perpetrate',\n",
       " 'sag',\n",
       " 'incompetent',\n",
       " 'proliferation',\n",
       " 'scarcity',\n",
       " 'owe',\n",
       " 'monstrous',\n",
       " 'gordon',\n",
       " 'preposterous',\n",
       " 'contain',\n",
       " 'compulsion',\n",
       " 'nosey',\n",
       " 'consternation',\n",
       " 'grenade',\n",
       " 'undesirable',\n",
       " 'remorse',\n",
       " 'indicate',\n",
       " 'impair',\n",
       " 'hater',\n",
       " 'malicious',\n",
       " 'insularity',\n",
       " 'mock',\n",
       " 'letterbox',\n",
       " 'malaise',\n",
       " 'tax',\n",
       " 'problem',\n",
       " 'salt',\n",
       " 'constraint',\n",
       " 'obliterate',\n",
       " 'uncharted',\n",
       " 'wto_term',\n",
       " 'corrode',\n",
       " 'tragedy',\n",
       " 'ambivalence',\n",
       " 'struggle',\n",
       " 'slink',\n",
       " 'recession',\n",
       " 'fanatical',\n",
       " 'cynicism',\n",
       " 'aspirational',\n",
       " 'prism',\n",
       " 'incompatible',\n",
       " 'decadent',\n",
       " 'weep',\n",
       " 'ear',\n",
       " 'clive_lewis',\n",
       " 'interdict',\n",
       " 'secede',\n",
       " 'strict',\n",
       " 'diversion',\n",
       " 'intrude',\n",
       " 'take_toll',\n",
       " 'repressive',\n",
       " 'wrongful',\n",
       " 'disappear',\n",
       " 'buckle',\n",
       " 'nonsense',\n",
       " 'devastate',\n",
       " 'consequence',\n",
       " 'massacre',\n",
       " 'corrosive',\n",
       " 'mar',\n",
       " 'scream',\n",
       " 'intrusion',\n",
       " 'impromptu',\n",
       " 'evasive',\n",
       " 'suffer',\n",
       " 'polity',\n",
       " 'cranky',\n",
       " 'absentee',\n",
       " 'nativists',\n",
       " 'blackout',\n",
       " 'bile',\n",
       " 'redundant',\n",
       " 'substandard',\n",
       " 'unarm',\n",
       " 'disinterest',\n",
       " 'wily',\n",
       " 'shoddy',\n",
       " 'mongering',\n",
       " 'fake',\n",
       " 'risk',\n",
       " 'voyage',\n",
       " 'euphoria',\n",
       " 'claim',\n",
       " 'sympathiser',\n",
       " 'painful',\n",
       " 'toil',\n",
       " 'insurgent',\n",
       " 'go',\n",
       " 'stray',\n",
       " 'complicity',\n",
       " 'miser',\n",
       " 'fled',\n",
       " 'outburst',\n",
       " 'expulsion',\n",
       " 'poverty',\n",
       " 'addiction',\n",
       " 'tardy',\n",
       " 'singular',\n",
       " 'butchery',\n",
       " 'split',\n",
       " 'collusion',\n",
       " 'truth',\n",
       " 'susceptible',\n",
       " 'obnoxious',\n",
       " 'uninformed',\n",
       " 'advantageous',\n",
       " 'mind',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
